{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse state networks \n",
    "Second-order dynamics on a physical network can be described by first-order dynamics on a second-order state network.\n",
    "\n",
    "We can represent this second-order network by it's _state transition matrix_ $P_{ij}$ with the probabilities for the random walker to transition from state node $i$ to state node $j$.\n",
    "\n",
    "In this view, we may note that some rows have similar probability distributions. We can measure how similar two probability distributions are with the [Jensen-Shannon Distance](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence).\n",
    "\n",
    "The idea behind sparse state networks is that we can lump state nodes (within each physical node) that constrain the network flow in a similar way without loosing (much) information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms to a general machine learning problem\n",
    "We will here solve the problem using standard [clustering algorithms](http://scikit-learn.org/stable/modules/clustering.html#clustering) from the [scikit-learn](http://scikit-learn.org/) package.\n",
    "\n",
    "In order to do that, we have to transform the state network into features usable for machine learning. We can do this with the help of the code in [state_lumping_network.py](./state_lumping_network.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_lumping_network import StateNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read state network from file '../data/toy_states.net'...\n",
      " -> StateNetwork (5 physical nodes, 12 state nodes and 32 links)\n"
     ]
    }
   ],
   "source": [
    "net = StateNetwork()\n",
    "net.readFromFile(\"../data/toy_states.net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![toy_states](../figures/toy_states_full.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix for the central physical node: \n",
      "[[0.4 0.4 0.1 0.1]\n",
      " [0.4 0.4 0.1 0.1]\n",
      " [0.1 0.1 0.4 0.4]\n",
      " [0.1 0.1 0.4 0.4]]\n",
      " rowToStateId: {0: 1, 1: 2, 2: 7, 3: 8}\n"
     ]
    }
   ],
   "source": [
    "X, rowToStateId = net.getFeatureMatrix(1)\n",
    "print(\"Feature matrix for the central physical node: \\n{}\\n rowToStateId: {}\".format(X, rowToStateId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `getFeatureMatrix` method removes all-zero rows and columns in the feature matrix but provides a mapping back to the original state network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster with scikit-learn\n",
    "Now we can compare rows pairwise and cluster the most similar rows together. The Jensen-Shannon distance is unfortunately not implemented in scikit-learn (though it exist in a [pull request](https://github.com/scikit-learn/scikit-learn/pull/4191)), but we can use for example `cosine` instead with similar result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels in feature matrix space: [1 1 0 0]\n",
      "Cluster labels in state node space: {1: 1, 2: 1, 7: 0, 8: 0}\n"
     ]
    }
   ],
   "source": [
    "model = cluster.AgglomerativeClustering(\n",
    "    linkage=\"complete\",\n",
    "    # affinity=jensen_shannon_distances,\n",
    "    affinity=\"cosine\",\n",
    "    n_clusters=2\n",
    ")\n",
    "\n",
    "labels = model.fit_predict(X)\n",
    "print(\"Cluster labels in feature matrix space: {}\\nCluster labels in state node space: {}\".format(\n",
    "    labels,\n",
    "    {rowToStateId[i]:clusterId for i,clusterId in enumerate(labels)}\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lump whole network\n",
    "We can provide a custom clustering algorithm to `StateNetwork`, where we get the feature matrix as input and should provide the cluster labels of that matrix back. With the clustering method above, we need to set the number of clusters, which we for this toy network can be set to half of the number of state nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureClusterFunction(clusterRate=0.5):\n",
    "    def calcClusters(X):\n",
    "        numStates, numFeatures = X.shape\n",
    "        if numStates < 2 or numFeatures < 2:\n",
    "            # Don't cluster if too small\n",
    "            return list(range(numStates))\n",
    "\n",
    "        # Can be an adaptive number of clusters based on entropy reduction\n",
    "        n_clusters = max(1, int(clusterRate * numStates))\n",
    "        model = cluster.AgglomerativeClustering(\n",
    "            linkage=\"complete\",\n",
    "            # affinity=jensen_shannon_distances,\n",
    "            affinity=\"cosine\",\n",
    "            n_clusters=n_clusters\n",
    "        )\n",
    "\n",
    "        labels = model.fit_predict(X)\n",
    "        return labels\n",
    "    return calcClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state nodes...\n",
      "Generate lumped state network from clustering...\n",
      " -> 6 state nodes and 16 links in lumped network.\n"
     ]
    }
   ],
   "source": [
    "net.clusterStateNodes(clusterFeatureMatrix=getFeatureClusterFunction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy rate before: 1.2406426982957872, after: 1.2406426982957874\n"
     ]
    }
   ],
   "source": [
    "h1 = net.calcEntropyRate()\n",
    "h2 = net.calcLumpedEntropyRate()\n",
    "print(\"Entropy rate before: {}, after: {}\".format(h1, h2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lumped state network to file '../output/toy_lumped.net'...\n",
      "# physical nodes: 5\n",
      "# state nodes: 12\n",
      "# lumped state nodes: 6\n",
      "*Vertices\n",
      "1 \"1\"\n",
      "2 \"2\"\n",
      "3 \"3\"\n",
      "4 \"4\"\n",
      "5 \"5\"\n",
      "*States\n",
      "#lumpedStateId physicalId lumpedStateIds\n",
      "1 1 \"[7, 8]\"\n",
      "2 1 \"[1, 2]\"\n",
      "3 2 \"[3, 4]\"\n",
      "4 3 \"[5, 6]\"\n",
      "5 4 \"[9, 10]\"\n",
      "6 5 \"[11, 12]\"\n",
      "*Links\n",
      "1 5 1.6\n",
      "1 6 1.6\n",
      "1 3 0.4\n",
      "1 4 0.4\n",
      "2 3 1.6\n",
      "2 4 1.6\n",
      "2 5 0.4\n",
      "2 6 0.4\n",
      "3 2 2.0\n",
      "3 4 2.0\n",
      "4 2 2.0\n",
      "4 3 2.0\n",
      "5 1 2.0\n",
      "5 6 2.0\n",
      "6 1 2.0\n",
      "6 5 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "net.writeLumpedStateNetwork(\"../output/toy_lumped.net\")\n",
    "print(Path('../output/toy_lumped.net').read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have generated the sparse network (with lossless compression)\n",
    "![toy_states](../figures/toy_states_full.png)\n",
    "![toy_states](../figures/toy_states_sparse.png)\n",
    "\n",
    "To the left, the original second-order network. To the right, the sparse network formed by lumping similar state nodes within each physical node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/toy_states.net:\n",
      "2 top modules with codelength 3.0114052384459713\n",
      "\n",
      "State level modules\n",
      "#stateId physicalId moduleIndex flow\n",
      "1 1 0 0.08333333333333333\n",
      "2 1 0 0.08333333333333333\n",
      "3 2 0 0.08333333333333333\n",
      "4 2 0 0.08333333333333333\n",
      "5 3 0 0.08333333333333333\n",
      "6 3 0 0.08333333333333333\n",
      "7 1 1 0.08333333333333334\n",
      "8 1 1 0.08333333333333334\n",
      "9 4 1 0.08333333333333334\n",
      "10 4 1 0.08333333333333334\n",
      "11 5 1 0.08333333333333334\n",
      "12 5 1 0.08333333333333334\n",
      "\n",
      "Physical level modules\n",
      "#physicalId moduleIndex flow\n",
      "1 0 0.16666666666666666\n",
      "2 0 0.16666666666666666\n",
      "3 0 0.16666666666666666\n",
      "1 1 0.16666666666666669\n",
      "4 1 0.16666666666666669\n",
      "5 1 0.16666666666666669\n",
      "\n",
      "--------------\n",
      "\n",
      "../output/toy_lumped.net:\n",
      "2 top modules with codelength 2.011405238445971\n",
      "\n",
      "State level modules\n",
      "#stateId physicalId moduleIndex flow\n",
      "1 1 0 0.16666666666666669\n",
      "5 4 0 0.16666666666666669\n",
      "6 5 0 0.16666666666666669\n",
      "2 1 1 0.16666666666666669\n",
      "3 2 1 0.16666666666666669\n",
      "4 3 1 0.16666666666666669\n",
      "\n",
      "Physical level modules\n",
      "#physicalId moduleIndex flow\n",
      "1 0 0.16666666666666669\n",
      "4 0 0.16666666666666669\n",
      "5 0 0.16666666666666669\n",
      "1 1 0.16666666666666669\n",
      "2 1 0.16666666666666669\n",
      "3 1 0.16666666666666669\n"
     ]
    }
   ],
   "source": [
    "def partition(inputFilename):\n",
    "    im = infomap.Infomap(\"--directed\")\n",
    "    im.network().readInputData(inputFilename)\n",
    "    im.run()\n",
    "    print(\"{}:\".format(inputFilename))\n",
    "    print(\"{} top modules with codelength {}\".format(im.numTopModules(), im.codelength()))\n",
    "    print(\"\\nState level modules\")\n",
    "    print(\"#stateId physicalId moduleIndex flow\")\n",
    "    for node in im.iterTree():\n",
    "        if node.isLeaf():\n",
    "            print(\"{} {} {} {}\".format(node.stateId, node.physicalId, node.moduleIndex(), node.data.flow))\n",
    "    print(\"\\nPhysical level modules\")\n",
    "    print(\"#physicalId moduleIndex flow\")\n",
    "    for node in im.iterTreePhysical():\n",
    "        if node.isLeaf():\n",
    "            print(\"{} {} {}\".format(node.physicalId, node.moduleIndex(), node.data.flow))\n",
    "\n",
    "partition(\"../data/toy_states.net\")\n",
    "print(\"\\n--------------\\n\")\n",
    "partition(\"../output/toy_lumped.net\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
