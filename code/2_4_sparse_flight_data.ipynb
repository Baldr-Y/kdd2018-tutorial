{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Sparse flight data\n", "\n", "A key question for the generation of sparse state networks is _how_ sparse. If we lump all state nodes with each physical node, we lose all higher-order information and may underfit. On the other hand, keeping all second-order state nodes may overfit.\n", "\n", "In this tutorial we will generate second-order state networks from path data and from there generate multiple sparse networks with different number of (lumped) state nodes and evaluate the result with Infomap"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Generate training and validation sets\n", "To get a bigger network, we can merge the flight path data from the four quarters (`\"data/air2015_{q}_paths.net\" for q in [1,2,3,4]`). But to evaluate the goodness of fit, we can split each path randomly in either a _training_ or a _validation_ set and write a path data file for each of the data set.\n", "\n", "**TODO:**\n", "- Write a function that merges all paths of the year and writes it to a _training_ paths file with 50% chance and to a _validation_ paths file otherwise. Skip the '*vertices' section"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Generate state networks from paths\n", "\n", "**TODO:**\n", "- Use Infomap to generate second-order state networks from the two paths data files."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Generate _sparse_ state networks\n", "\n", "Here we will generate multiple lumped state networks with different amount of state nodes. A simple way is to parameterise this with a cluster rate $r$ going from 0.1 to 1, where `n_clusters = max(1, int(r * numStateNodes)`. For convenience, you can just send in the argument `clusterRate` to `clusterStateNodes` to achieve this, instead of the cluster function in the previous tutorial.\n", "\n", "**TODO:**\n", "- Read in the training network with `StateNetwork`\n", "- Calculate entropy rate\n", "- Cluster the network for all cluster rates $r$ in for example `np.linspace(0.1, 1, 10)`.\n", "- Save the number of lumped state nodes and the lumped entropy rate"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### How much information do we lose as we reduce the number of state nodes?\n", "\n", "**TODO:**\n", "- Plot the entropy rate against the number of state nodes\n", "- Check that the entropy rates approaches the original one and coincides at cluster rate $r = 1$"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Note that the original number of state nodes can be much larger than the maximum in the lumped state networks due to dangling nodes which are lumped implicitly."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Validate with Infomap\n", "The goal here is to calculate the codelength for the validation network, given the different partitions found on the lumped training networks.\n", "\n", "**TODO:**\n", "- Run Infomap on all lumped state networks and write a `.tree` file for each and store codelength\n", "- Run Infomap on the validation network but with cluster data from external file for all `.tree` files generated from the lumped networks and store the codelength\n", "- Plot the training and validation codelengths against the number of state nodes and check if there is an optimum that balances underfit and overfit"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.5"}}, "nbformat": 4, "nbformat_minor": 2}